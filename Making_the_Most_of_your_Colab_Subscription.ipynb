{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijayyovan/MLOpsPython/blob/master/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMXjkKUS73r3"
      },
      "source": [
        "# Google Colab is available in VS Code!\n",
        "![logo.webp](data:image/webp;base64,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)\n",
        "\n",
        "Try the new [Google Colab extension](https://marketplace.visualstudio.com/items?itemName=Google.colab) for Visual Studio Code. You can get up and running in just a few clicks:\n",
        "\n",
        "*  In VS Code, open the ***Extensions*** view and search for 'Google Colab' to install.\n",
        "*  Open the kernel selector by creating or opening any `.ipynb` notebook file in your local workspace and either running a cell or clicking the ***Select Kernel*** button in the top right.\n",
        "*  Click ***Colab*** and then select your desired runtime, sign in with your Google account, and you're all set!\n",
        "\n",
        "See more details in our [announcement blog here](https://developers.googleblog.com/google-colab-is-coming-to-vs-code)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjTLZD16HebW"
      },
      "source": [
        "# Access Popular LLMs via Google-Colab-AI Without an API Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwVZpSEoHkQH"
      },
      "source": [
        "Users with Colab's paid plans have free access to most popular LLMs via google-colab-ai Python library. For more details, refer to the [getting started with google colab ai](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Getting_started_with_google_colab_ai.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebl8tzi917TU"
      },
      "outputs": [],
      "source": [
        "from google.colab import ai\n",
        "response = ai.generate_text(\"What is the capital of France?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Intro to RAPIDS cuDF to accelerate pandas](https://nvda.ws/rapids-cudf)\n",
        "- [Getting Started with cuML's accelerator mode](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cuml_sklearn_colab_demo.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [Train a CNN to classify handwritten digits on the MNIST dataset using Flax NNX API](https://colab.research.google.com/github/google/flax/blob/main/docs_nnx/mnist_tutorial.ipynb)\n",
        "- [Train a Vision Transformer (ViT) for image classification with JAX](https://colab.research.google.com/github/jax-ml/jax-ai-stack/blob/main/docs/source/JAX_Vision_transformer.ipynb)\n",
        "- [Text classification with a transformer language model using JAX](https://colab.research.google.com/github/jax-ml/jax-ai-stack/blob/main/docs/source/JAX_transformer_text_classification.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mkHc00itWdDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Train a miniGPT language model with JAX AI Stack](https://docs.jaxstack.ai/en/latest/JAX_for_LLM_pretraining.html)\n",
        "- [LoRA/QLoRA finetuning for LLM using Tunix](https://github.com/google/tunix/blob/main/examples/qlora_gemma.ipynb)\n",
        "- [Parameter-efficient fine-tuning of Gemma with LoRA and QLoRA](https://keras.io/examples/keras_recipes/parameter_efficient_finetuning_of_gemma_with_lora_and_qlora/)\n",
        "- [Loading Hugging Face Transformers Checkpoints](https://keras.io/keras_hub/guides/hugging_face_keras_integration/)\n",
        "- [8-bit Integer Quantization in Keras](https://keras.io/guides/int8_quantization_in_keras/)\n",
        "- [Float8 training and inference with a simple Transformer model](https://keras.io/examples/keras_recipes/float8_training_and_inference_with_transformer/)\n",
        "- [Pretraining a Transformer from scratch with KerasHub](https://keras.io/keras_hub/guides/transformer_pretraining/)\n",
        "- [Simple MNIST convnet](https://keras.io/examples/vision/mnist_convnet/)\n",
        "- [Image classification from scratch using Keras 3](https://keras.io/examples/vision/image_classification_from_scratch/)\n",
        "- [Image Classification with KerasHub](https://keras.io/keras_hub/guides/classification_with_keras_hub/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File operations\n",
        "\n",
        "## File Modes in Python\n",
        "\n",
        "| Mode | Meaning      | Pointer Start | Wipes File? | Creates File? | Usage |\n",
        "|------|-------------|--------------|------------|--------------|------|\n",
        "| r    | Read Only   | Beginning    | No         | No           | Standard Reading |\n",
        "| w    | Write Only  | Beginning    | Yes        | Yes          | Fresh Start |\n",
        "| a    | Append      | End          | No         | Yes          | Add Content |\n",
        "| r+   | Read+Write  | Beginning    | No         | No           | Modify Existing |\n",
        "| w+   | Write+Read  | Beginning    | Yes        | Yes          | Overwrite |\n",
        "| a+   | Append+Read | End          | No         | Yes          | Read & Add |\n"
      ],
      "metadata": {
        "id": "f2cajYkuga8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"\"\"Hello Vijay,\n",
        "\n",
        "This is a sample text file created in Google Colab.\n",
        "\n",
        "You can write any content you want here, such as:\n",
        "- Notes\n",
        "- Output logs\n",
        "- Configuration details\n",
        "- Training results\n",
        "\n",
        "Regards,\n",
        "ChatGPT\n",
        "\"\"\"\n",
        "\n",
        "with open(\"temp_1.txt\", \"w\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"File created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5h1Qo96VuMV",
        "outputId": "3bd3f4ed-727c-490f-e4c9-947df9711ddb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File Modes Full Example Program\n",
        "\n",
        "# File name\n",
        "filename = \"temp_1.txt\"\n",
        "\n",
        "# ✅ Step 0: Create the file with initial content\n",
        "print(\"=== Creating temp_1.txt with initial content ===\")\n",
        "\n",
        "with open(filename, \"w\") as f:\n",
        "    f.write(\"Welcome to data science bootcamp\\n\")\n",
        "    f.write(\"-- Welcome to data science bootcamp\")\n",
        "\n",
        "print(\"Initial file created!\\n\")\n",
        "\n",
        "\n",
        "# ✅ 1. Read Mode ('r')\n",
        "print(\"=== 1. Reading File using 'r' mode ===\")\n",
        "\n",
        "with open(filename, \"r\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "\n",
        "# ✅ 2. Append Mode ('a')\n",
        "print(\"\\n=== 2. Appending using 'a' mode ===\")\n",
        "\n",
        "with open(filename, \"a\") as f:\n",
        "    f.write(\"\\nAdding this line with append mode.\")\n",
        "\n",
        "print(\"Append complete!\")\n",
        "\n",
        "\n",
        "# ✅ 3. Read + Write Mode ('r+')\n",
        "print(\"\\n=== 3. Using 'r+' mode (Read + Write) ===\")\n",
        "\n",
        "with open(filename, \"r+\") as f:\n",
        "    content = f.read()\n",
        "    print(\"File content length:\", len(content))\n",
        "\n",
        "    # Writing at the end (cursor is at the end after read)\n",
        "    f.write(\"\\nUpdated with r+ mode.\")\n",
        "\n",
        "print(\"r+ update complete!\")\n",
        "\n",
        "\n",
        "# ✅ Final Content of temp_1.txt\n",
        "print(\"\\n=== Final Content of temp_1.txt ===\")\n",
        "\n",
        "with open(filename, \"r\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "\n",
        "# ✅ 4. Write + Read Mode ('w+')\n",
        "print(\"\\n=== 4. Using 'w+' mode (Overwrite + Read) ===\")\n",
        "\n",
        "with open(\"temp_2.txt\", \"w+\") as f:\n",
        "    f.write(\"This file was created/cleared using w+ mode.\")\n",
        "    f.seek(0)\n",
        "\n",
        "    print(\"\\nContent of temp_2.txt:\")\n",
        "    print(f.read())\n",
        "\n",
        "\n",
        "print(\"\\n✅ All operations complete successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsCkrKOyZnC0",
        "outputId": "9b5f1808-b903-43aa-e265-c8cf443e2abf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Creating temp_1.txt with initial content ===\n",
            "Initial file created!\n",
            "\n",
            "=== 1. Reading File using 'r' mode ===\n",
            "Welcome to data science bootcamp\n",
            "-- Welcome to data science bootcamp\n",
            "\n",
            "=== 2. Appending using 'a' mode ===\n",
            "Append complete!\n",
            "\n",
            "=== 3. Using 'r+' mode (Read + Write) ===\n",
            "File content length: 103\n",
            "r+ update complete!\n",
            "\n",
            "=== Final Content of temp_1.txt ===\n",
            "Welcome to data science bootcamp\n",
            "-- Welcome to data science bootcamp\n",
            "Adding this line with append mode.\n",
            "Updated with r+ mode.\n",
            "\n",
            "=== 4. Using 'w+' mode (Overwrite + Read) ===\n",
            "\n",
            "Content of temp_2.txt:\n",
            "This file was created/cleared using w+ mode.\n",
            "\n",
            "✅ All operations complete successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"temp_1.txt\", \"a+\") as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1alKqCRYZsFD",
        "outputId": "fe736376-d045-4169-9177-acaf6e17d9cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What if i want to add new content in the middle of file, using f.seek()"
      ],
      "metadata": {
        "id": "1on85dPBbKbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"temp_1.txt\", \"a+\") as f:\n",
        "    print(f\"Initial pointer: {f.tell()}\")\n",
        "    f.write(\"print('hwllo world'))\")\n",
        "    print(f\"Pointer after write: {f.tell()}\")\n",
        "\n",
        "    # Note: In 'a+' mode, write() always appends to the end regardless of seek()\n",
        "    f.seek(3)\n",
        "    f.write(\"****\")\n",
        "\n",
        "    # To read the whole file, we must seek back to the start\n",
        "    f.seek(0)\n",
        "    all_contents = f.read()\n",
        "    print(\"\\nFile Content:\")\n",
        "    print(all_contents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK38-EPZa_IT",
        "outputId": "c349dca4-d64c-414d-fa29-5045046b95b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial pointer: 150\n",
            "Pointer after write: 171\n",
            "\n",
            "File Content:\n",
            "Welcome to data science bootcamp\n",
            "-- Welcome to data science bootcamp\n",
            "Adding this line with append mode.\n",
            "Updated with r+ mode.print('hwllo world'))****print('hwllo world'))****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# a, a+ -> always append"
      ],
      "metadata": {
        "id": "AogXuEd9cqK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with open(\"temp_1.txt, \"w+\") as f:\n",
        "  first_index = f.tell()\n",
        "  print(first_index)\n",
        "\n",
        "  f.write(\"hello world\")\n",
        "\n",
        "  last_index = f.tell()\n",
        "  print(last_index)\n",
        "\n",
        "  middle_index = (last_index / 2) + 1\n",
        "\n",
        "  print(middle_index)\n",
        "\n",
        "  f.seek(middle_index)\n",
        "  f.write(\"***\")\n",
        "  printa(f.tell())\n",
        "  print(all_contents)"
      ],
      "metadata": {
        "id": "BCRTWjyfcvxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"temp_1.txt\", \"w+\") as f:\n",
        "  first_index = f.tell()\n",
        "  print(first_index)\n",
        "\n",
        "  f.write(\"hello world\")\n",
        "\n",
        "  last_index = f.tell()\n",
        "  print(last_index)\n",
        "\n",
        "  middle_index = (last_index / 2) + 1\n",
        "\n",
        "  print(middle_index)\n",
        "\n",
        "  f.seek(middle_index)\n",
        "  f.write(\"***\")\n",
        "  print(f.tell())\n",
        "  print(all_contents)"
      ],
      "metadata": {
        "id": "rccxX7gRdxPr",
        "outputId": "0e30b457-3370-49ae-ff72-08ded8975f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "11\n",
            "6.5\n",
            "9\n",
            "Welcome to data science bootcamp\n",
            "-- Welcome to data science bootcamp\n",
            "Adding this line with append mode.\n",
            "Updated with r+ mode.print('hwllo world'))****print('hwllo world'))****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment\n",
        "\n",
        "# Add new data in the middle of the file without overwriting the exiting content\n",
        "\n",
        "# r+ -->\n",
        "\n",
        "# w + --> f.write(), f.seek()\n",
        "\n",
        "\n",
        "\n",
        "# from_center = f.read()\n",
        "content\n",
        "\n",
        "# f.write(\"***\")\n",
        "# new_pointer_loc = f.seek()\n"
      ],
      "metadata": {
        "id": "GdJJ1F0yeSY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"temp_2.txt\", \"w\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"File created successfully!\")"
      ],
      "metadata": {
        "id": "2MAoFpngd7MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YyeJLQ6reP38"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}